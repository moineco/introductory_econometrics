{
  "hash": "98f546f107bee9710fb64f6ef9af7963",
  "result": {
    "markdown": "# Tobit Models\n\nThe tobit model, also called a censored regression model, is designed to estimate linear relationships between variables when there is either left- or right-censoring in the dependent variable.\n\n- Censoring from above takes place when cases with a value at or above some threshold, all take on the value of that threshold, so that the true value might be equal to the threshold, but it might also be higher. \n\n- In the case of censoring from below, values those that fall at or below some threshold are censored.\n\n## Install packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(GGally)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n```\n:::\n\n```{.r .cell-code}\nlibrary(VGAM)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: stats4\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: splines\n```\n:::\n\n```{.r .cell-code}\nlibrary(stargazer)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nPlease cite as: \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n Hlavac, Marek (2022). stargazer: Well-Formatted Regression and Summary Statistics Tables.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n R package version 5.2.3. https://CRAN.R-project.org/package=stargazer \n```\n:::\n:::\n\n\n## Useful data\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- read.csv(\"data/tobit.csv\")\n```\n:::\n\n\nThe dataset contains 200 observations. \n\n- The academic aptitude variable is \"apt\", the reading test scores are \"read\" and math test scores are \"math\". \n\n- The variable prog is the type of program the student is in, it is a categorical (nominal) variable that takes on three values, academic (prog = 1), general (prog = 2), and vocational (prog = 3). \n\n- The variable id is an identification variable.\n\nNow letâ€™s look at the data descriptively. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       id              read            math            prog      \n Min.   :  1.00   Min.   :28.00   Min.   :33.00   Min.   :1.000  \n 1st Qu.: 50.75   1st Qu.:44.00   1st Qu.:45.00   1st Qu.:2.000  \n Median :100.50   Median :50.00   Median :52.00   Median :2.000  \n Mean   :100.50   Mean   :52.23   Mean   :52.65   Mean   :2.025  \n 3rd Qu.:150.25   3rd Qu.:60.00   3rd Qu.:59.00   3rd Qu.:2.250  \n Max.   :200.00   Max.   :76.00   Max.   :75.00   Max.   :3.000  \n      apt       \n Min.   :352.0  \n 1st Qu.:575.5  \n Median :633.0  \n Mean   :640.0  \n 3rd Qu.:705.2  \n Max.   :800.0  \n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nf <- function(x, var, bw = 15) {\n  dnorm(x, mean = mean(var), sd(var)) * length(var)  * bw\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np <- ggplot(data, aes(x = apt, fill=prog))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np + stat_bin(binwidth=15) +\n  stat_function(fun = f, size = 1,\n    args = list(var = data$apt))\n```\n\n::: {.cell-output-display}\n![](lecture_14_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np + stat_bin(binwidth = 1) + stat_function(fun = f, size = 1, args = list(var = data$apt, \n    bw = 1))\n```\n\n::: {.cell-output-display}\n![](lecture_14_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncor(data[, c(\"read\", \"math\", \"apt\")])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          read      math       apt\nread 1.0000000 0.6622801 0.6451215\nmath 0.6622801 1.0000000 0.7332702\napt  0.6451215 0.7332702 1.0000000\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggpairs(data[, c(\"read\", \"math\", \"apt\")])\n```\n\n::: {.cell-output-display}\n![](lecture_14_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(m <- vglm(apt ~ read + math + prog, tobit(Upper = 800), data = data))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nvglm(formula = apt ~ read + math + prog, family = tobit(Upper = 800), \n    data = data)\n\nCoefficients: \n               Estimate Std. Error z value Pr(>|z|)    \n(Intercept):1 222.29186   34.25181   6.490 8.59e-11 ***\n(Intercept):2   4.18746    0.05236  79.973  < 2e-16 ***\nread            2.78781    0.61397   4.541 5.61e-06 ***\nmath            6.11310    0.67896   9.004  < 2e-16 ***\nprog          -22.74852    6.86965  -3.311 0.000928 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nNames of linear predictors: mu, loglink(sd)\n\nLog-likelihood: -1041.533 on 395 degrees of freedom\n\nNumber of Fisher scoring iterations: 5 \n\nNo Hauck-Donner effect found in any of the estimates\n```\n:::\n:::\n",
    "supporting": [
      "lecture_14_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}