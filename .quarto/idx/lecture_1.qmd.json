{"title":"Nature and scope of Econometrics","markdown":{"headingText":"Nature and scope of Econometrics","containsRefs":false,"markdown":"\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```\n\n```{r, echo=FALSE}\nknitr::opts_chunk$set(error = TRUE)\n```\n\n# Introductory Econometrics\n\n## Install packages\n\n```{r, message=FALSE}\nlibrary(wooldridge)\nlibrary(readr)\nlibrary(stargazer)\nlibrary(kableExtra)\nlibrary(quantmod)\nlibrary(xts) \n```\n\n## Useful dataset\n\n```{r}\nearns <- read.csv(\"data/earns.csv\")\ngpa1 <- read.csv(\"data/gpa1.csv\")\nhprice1 <- read.csv(\"data/hprice1.csv\")\nhprice2 <- read.csv(\"data/hprice2.csv\")\nhprice3 <- read.csv(\"data/hprice3.csv\")\njtrain <- read.csv(\"data/jtrain.csv\")\nnyse <- read.csv(\"data/nyse.csv\")\nphillips <- read.csv(\"data/phillips.csv\")\nrdchem <- read.csv(\"data/rdchem.csv\")\ntraffic1 <- read.csv(\"data/traffic1.csv\")\nwage1 <- read.csv(\"data/wage1.csv\")\n```\n\n## Simple regression model\n\n### **`Example 1:` A log wage equation**\n\n-   Load the `wage1` data and check out the documentation.\n\n$educ$: years of education\n\n$wage$: average hourly earnings\n\n$lwage$: log of the average hourly earnings\n\n-   First, make a scatter-plot of the two variables and look for possible patterns in the relationship between them.\n\n```{r}\nplot(y = wage1$wage, x = wage1$educ, col = \"black\", pch = 21, bg = \"orange\",     \n     cex=1.25, xaxt=\"n\", frame = FALSE, main = \"Wages vs. Education, 1976\", \n     xlab = \"years of education\", ylab = \"Hourly wages\")\naxis(side = 1, at = c(0,6,12,18))\nrug(wage1$wage, side=2, col=\"black\")\n```\n\n1.  It appears that ***on average***, more years of education, leads to higher wages.\n\n2.  The example in the text is interested in the *return to another year of education*, or what the ***percentage*** change in wages one might expect for each additional year of education. To do so, one must use the $log($`wage`$)$. This has already been computed in the data set and is defined as `lwage`.\n\n-   Build a linear model to estimate the relationship between the *log of wage* (`lwage`) and *education* (`educ`).\n\n$$\\widehat{log(wage)} = \\beta_0 + \\beta_1educ$$\n\n```{r, echo = TRUE, warning=FALSE}\nlog_wage_model <- lm(lwage ~ educ, data = wage1)\n```\n\n-   Print the `summary` of the results.\n\n```{r, echo = TRUE, warning=FALSE}\nsummary(log_wage_model)\n```\n\n-   Use the `stargazer` package to make beautiful table\n\n```{r, results = 'asis', echo = TRUE, warning = FALSE, message = FALSE}\nstargazer(type = \"html\", log_wage_model, single.row = TRUE, header = FALSE, digits = 3)\n```\n\n-   Plot the $log($`wage`$)$ vs `educ`. The blue line represents the least squares fit.\n\n```{r, echo=TRUE}\nplot(y = wage1$lwage, x = wage1$educ, main = \"A Log Wage Equation\", \n     col = \"orange\", pch = 21, bg = \"black\", cex=1.25,\n     xlab = \"years of education\", ylab = \"log of average hourly wages\",\n     xaxt=\"n\", frame = FALSE)\naxis(side = 1, at = c(0,6,12,18))\nabline(log_wage_model, col = \"black\", lwd=2)\nrug(wage1$lwage, side=2, col=\"black\")\n```\n\n## Multiple regression analysis\n\n### **`Example 2:` Hourly wage equation**\n\nCheck the documentation for variable information\n\n$lwage$: log of the average hourly earnings\n\n$educ$: years of education\n\n$exper$: years of potential experience\n\n$tenutre$: years with current employer\n\n-   Plot the variables against `lwage` and compare their distributions and slope ($\\beta$) of the simple regression lines\n\n```{r, fig.height=3, echo=TRUE}\npar(mfrow=c(1,3))\nplot(y = wage1$lwage, x = wage1$educ, col=\"orange\", xaxt=\"n\", frame = FALSE, main = \"years of education\", xlab = \"\", ylab = \"\")\nmtext(side=2, line=2.5, \"Hourly wages\", cex=1.25)\naxis(side = 1, at = c(0,6,12,18))\nabline(lm(lwage ~ educ, data=wage1), col = \"black\", lwd=2)\nplot(y = wage1$lwage, x = wage1$exper, col=\"orange\", xaxt=\"n\", frame = FALSE, main = \"years of experience\", xlab = \"\", ylab = \"\")\naxis(side = 1, at = c(0,12.5,25,37.5,50))\nabline(lm(lwage ~ exper, data=wage1), col = \"black\", lwd=2)\nplot(y = wage1$lwage, x = wage1$tenure, col=\"orange\", xaxt=\"n\", frame = FALSE, main = \"years with employer\", xlab = \"\", ylab = \"\")\naxis(side = 1, at = c(0,11,22,33,44))\nabline(lm(lwage ~ tenure, data=wage1), col = \"black\", lwd=2)\n```\n\n-   Estimate the model regressing *educ*, *exper*, and *tenure* against *log(wage)*.\n\n$$\\widehat{log(wage)} = \\beta_0 + \\beta_1educ + \\beta_3exper + \\beta_4tenure$$\n\n```{r}\nhourly_wage_model <- lm(lwage ~ educ + exper + tenure, data = wage1)\n```\n\n-   Print the estimated model coefficients:\n\n```{r, eval=FALSE}\ncoefficients(hourly_wage_model)\n```\n\n```{r, echo=TRUE}\nkable(coefficients(hourly_wage_model), digits=4, col.names = \"Coefficients\", align = 'l')\n```\n\n-   Plot the coefficients, representing percentage impact of each variable on $log($`wage`$)$ for a quick comparison.\n\n```{r, echo=TRUE}\nbarplot(sort(100*hourly_wage_model$coefficients[-1]), horiz=TRUE, las=1,\n        ylab = \" \", main = \"Coefficients of Hourly Wage Equation\")\n```\n\n## Multiple regression analysis: inference\n\n### **`Example 3:` Hourly Wage Equation**\n\nUsing the same model estimated in **`example 3`**, examine and compare the standard errors associated with each coefficient. Like the textbook, these are contained in parenthesis next to each associated coefficient.\n\n```{r}\nsummary(hourly_wage_model)\n```\n\n```{r, results='asis', echo=TRUE, warning=FALSE, message=FALSE}\nstargazer(type = \"html\", hourly_wage_model,  single.row = TRUE, header = FALSE, digits=5)\n```\n\nFor the years of experience variable, or `exper`, use coefficient and Standard Error to compute the $t$ statistic:\n\n$$t_{exper} = \\frac{0.004121}{0.001723} = 2.391$$\n\nFortunately, `R` includes $t$ statistics in the `summary` of model diagnostics.\n\n```{r, eval=TRUE}\nsummary(hourly_wage_model)$coefficients\n```\n\n```{r, echo=TRUE}\nkable(summary(hourly_wage_model)$coefficients, align=\"l\", digits=3)\n```\n\n-   lets plot this results\n\n```{r, fig.height=8}\npar(mfrow=c(2,2))\nplot(y = hourly_wage_model$residuals, x = hourly_wage_model$fitted.values , col=\"orange\", xaxt=\"n\", \n     frame = FALSE, main = \"Fitted Values\", xlab = \"\", ylab = \"\")\nmtext(side=2, line=2.5, \"Model Residuals\", cex=1.25)\nabline(0, 0, col = \"black\", lty=2, lwd=2)\nplot(y = hourly_wage_model$residuals, x = wage1$educ, col=\"green\", xaxt=\"n\", \n     frame = FALSE, main = \"years of education\", xlab = \"\", ylab = \"\")\naxis(side = 1, at = c(0,6,12,18))\nabline(0, 0, col = \"black\", lty=2, lwd=2)\nplot(y = hourly_wage_model$residuals, x = wage1$exper, col=\"gray\", xaxt=\"n\", \n     frame = FALSE, main = \"years of experience\", xlab = \"\", ylab = \"\")\nmtext(side=2, line=2.5, \"Model Residuals\", cex=1.25)\naxis(side = 1, at = c(0,12.5,25,37.5,50))\nabline(0, 0, col = \"black\", lty=2, lwd=2)\nplot(y = hourly_wage_model$residuals, x = wage1$tenure, col=\"blue\", xaxt=\"n\", \n     frame = FALSE, main = \"years with employer\", xlab = \"\", ylab = \"\")\naxis(side = 1, at = c(0,11,22,33,44))\nabline(0, 0, col = \"black\", lty=2, lwd=2)\n```\n\n-   Plot the $t$ statistics for a visual comparison:\n\n```{r, echo=TRUE}\nbarplot(sort(summary(hourly_wage_model)$coefficients[-1, \"t value\"]), horiz=TRUE, las=1, \n        ylab = \" \", main = \"t statistics of Hourly Wage Equation\")\n```\n\n### **`Example 4:` Effect of Job Training on Firm Scrap Rates**\n\n-   Load the `jtrain` data set. (From H. Holzer, R. Block, M. Cheatham, and J. Knott (1993), *Are Training Subsidies Effective? The Michigan Experience*, Industrial and Labor Relations Review 46, 625-636. The authors kindly provided the data.)\n\n$year:$ 1987, 1988, or 1989\n\n$union:$ =1 if unionized\n\n$lscrap:$ Log(scrap rate per 100 items)\n\n$hrsemp:$ (total hours training) / (total employees trained)\\\n$lsales:$ Log(annual sales, \\$)\n\n$lemploy:$ Log(umber of employees at plant)\n\n-   First, use the `subset` function and it's argument by the same name to return observations which occurred in **1987** and are not **union**.\n\n-   At the same time, use the `select` argument to return only the variables of interest for this problem.\n\n```{r}\njtrain_subset <- subset(jtrain, subset = (year == 1987 & union == 0), select = c(year, union, lscrap, hrsemp, lsales, lemploy))\n```\n\n-   Next, test for missing values. One can \"eyeball\" these with R Studio's `View` function, but a more precise approach combines the `sum` and `is.na` functions to return the total number of observations equal to `NA`.\n\n```{r}\nsum(is.na(jtrain_subset))\n```\n\n-   While `R`'s `lm` function will automatically remove missing `NA` values, eliminating these manually will produce more clearly proportioned graphs for exploratory analysis. Call the `na.omit` function to remove all missing values and assign the new `data.frame` object the name **`jtrain_clean`**.\n\n```{r}\njtrain_clean <- na.omit(jtrain_subset)\n```\n\n-   We use `jtrain_clean` to plot the variables of interest against `lscrap`. Visually observe the respective distributions for each variable, and compare the slope ($\\beta$) of the simple regression lines.\n\n```{r, echo=TRUE, fig.height=3}\npar(mfrow=c(1,3))\npoint_size <- 1.60\nplot(y = jtrain_clean$lscrap, x = jtrain_clean$hrsemp, frame = FALSE, \nmain = \"Total (hours/employees) trained\", ylab = \"\", xlab=\"\", pch = 21, bg = \"lightgrey\", cex=point_size)\nmtext(side=2, line=2, \"Log(scrap rate)\", cex=1.25)\nabline(lm(lscrap ~ hrsemp, data=jtrain_clean), col = \"black\", lwd=2)\nplot(y = jtrain_clean$lscrap, x = jtrain_clean$lsales, frame = FALSE, main = \"Log(annual sales $)\", ylab = \" \", xlab=\"\", pch = 21, bg = \"lightgrey\", cex=point_size)\nabline(lm(lscrap ~ lsales, data=jtrain_clean), col = \"black\", lwd=2)\nplot(y = jtrain_clean$lscrap, x = jtrain_clean$lemploy, frame = FALSE, main = \"Log(# employees at plant)\", ylab = \" \", xlab=\"\", pch = 21, bg = \"lightgrey\", cex=point_size)\nabline(lm(lscrap ~ lemploy, data=jtrain_clean), col = \"black\", lwd=2)\n```\n\n-   Now create the linear model regressing `hrsemp`(total hours training/total employees trained), `lsales`(log of annual sales), and `lemploy`(the log of the number of the employees), against `lscrap`(the log of the scrape rate).\n\n$$lscrap = \\alpha + \\beta_1 hrsemp + \\beta_2 lsales + \\beta_3 lemploy$$\n\n```{r}\nlinear_model <- lm(lscrap ~ hrsemp + lsales + lemploy, data = jtrain_clean)\n```\n\n-   Finally, print the complete summary diagnostics of the model.\n\n```{r, eval=TRUE, warning=FALSE, message=FALSE}\nsummary(linear_model)\n```\n\n-   Use `stargazer` to create representative table\n\n```{r, results='asis', echo=TRUE, warning=FALSE, message=FALSE}\nstargazer(type = \"html\", linear_model, single.row = TRUE, header = FALSE, digits=5)\n```\n\n```{r, echo=TRUE, eval=TRUE}\ncoefficient <- coef(linear_model)[-1]\n confidence <- confint(linear_model, level = 0.95)[-1,]\ngraph <- drop(barplot(coefficient, ylim = range(c(confidence)),\n              main = \"Coefficients & 95% C.I. of variables on Firm Scrap Rates\"))  \narrows(graph, coefficient, graph, confidence[,1], angle=90, length=0.55, col=\"black\", lwd=2)\narrows(graph, coefficient, graph, confidence[,2], angle=90, length=0.55, col=\"black\", lwd=2)\n```\n\n## Chapter 5: Multiple Regression Analysis: OLS Asymptotics\n\n### **`Example:` Housing Prices and Distance From an Incinerator**\n\n-   We will use the `hprice3` data set.\n\n$lprice:$ Log(selling price)\n\n$ldist:$ Log(distance from house to incinerator, feet)\n\n$larea:$ Log(square footage of house)\n\n-   Graph the prices of housing against distance from an incinerator:\n\n```{r, echo=TRUE, fig.align='center'}\npar(mfrow=c(1,2))\nplot(y = hprice3$price, x = hprice3$dist, main = \" \", xlab = \"Distance to Incinerator in feet\", ylab = \"Selling Price\",  frame = FALSE, pch = 21, bg = \"lightgrey\")\nabline(lm(price ~ dist, data=hprice3), col = \"black\", lwd=2)\n```\n\n-   Next, model the $log($`price`$)$ against the $log($`dist`$)$ to estimate the percentage relationship between the two.\n\n$$price = \\alpha + \\beta_1 dist$$\n\n```{r}\nprice_dist_model <- lm(lprice ~ ldist, data = hprice3)\n```\n\n-   Create another model that controls for \"quality\" variables, such as square footage `area` per house.\n\n$$price = \\alpha + \\beta_1 dist + \\beta_2 area$$\n\n```{r}\nprice_area_model <- lm(lprice ~ ldist + larea, data = hprice3)\n```\n\n-   Compare the coefficients of both models. Notice that adding `area` improves the quality of the model, but also reduces the coefficient size of `dist`.\n\n```{r, eval=TRUE}\nsummary(price_dist_model)\nsummary(price_area_model)\n```\n\n-   Use *`stargazer`* for better table\n\n```{r, results='asis', echo=TRUE, warning=FALSE, message=FALSE}\nstargazer(type = \"html\",price_dist_model, price_area_model,  single.row = TRUE, header = FALSE, digits=5)\n```\n\n-   Graphing illustrates the larger coefficient for `area`\n\n```{r, echo=FALSE}\npar(mfrow=c(1,2))\npoint_size <- 0.80\nplot(y = hprice3$lprice, x = hprice3$ldist, frame = FALSE, \nmain = \"Log(distance from incinerator)\", ylab = \"\", xlab=\"\", \npch = 21, bg = \"lightgrey\", cex=point_size)\nmtext(side=2, line=2, \"Log( selling price )\", cex=1.25)\nabline(lm(lprice ~ ldist, data=hprice3), col = \"black\", lwd=2)\nplot(y = hprice3$lprice, x = hprice3$larea, frame = FALSE, main = \"Log(square footage of house)\", ylab = \" \", xlab=\"\", pch = 21, bg = \"lightgrey\", cex=point_size)\nabline(lm(lprice ~ larea, data=hprice3), col = \"black\", lwd=2)\n```\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"lecture_1.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.1.165","bibliography":["references.bib"],"editor":"visual","theme":"cosmo"},"extensions":{"book":{"multiFile":true}}},"pdf":{"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","output-file":"lecture_1.pdf"},"language":{},"metadata":{"block-headings":true,"bibliography":["references.bib"],"editor":"visual","documentclass":"scrreprt"},"extensions":{"book":{}}}}}